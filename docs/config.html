<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Configuration - oxicrab</title>
  <meta name="description" content="Complete configuration reference for oxicrab. Models, credentials, agent defaults, cost guard, circuit breaker, and logging.">
  <meta name="theme-color" content="#0ea5e9">
  <link rel="icon" href="oxicrab.png">
  <style>
    :root {
      --bg: #fafbfc; --bg-alt: #f0f4f8; --bg-dark: #0b1222;
      --text: #1e293b; --text-muted: #64748b; --text-light: #94a3b8;
      --accent: #0ea5e9; --accent-dark: #0284c7;
      --coral: #f97066; --teal: #14b8a6; --purple: #8b5cf6;
      --border: #e2e8f0; --surface: #fff;
      --code-bg: #0f172a; --code-text: #e2e8f0;
      --max-w: 820px;
      --mono: 'IBM Plex Mono', 'SF Mono', 'Cascadia Code', Consolas, monospace;
      --sans: 'IBM Plex Sans', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
    }
    * { margin: 0; padding: 0; box-sizing: border-box; }
    html { scroll-behavior: smooth; }
    body { font-family: var(--sans); background: var(--bg); color: var(--text); line-height: 1.7; -webkit-font-smoothing: antialiased; }

    /* NAV */
    nav { position: sticky; top: 0; background: rgba(250,251,252,0.9); backdrop-filter: blur(12px); border-bottom: 1px solid var(--border); z-index: 100; padding: 0 2rem; }
    .nav-inner { max-width: 1120px; margin: 0 auto; display: flex; align-items: center; justify-content: space-between; height: 56px; }
    .nav-logo { font-family: var(--mono); font-weight: 700; font-size: 1.1rem; color: var(--text); text-decoration: none; letter-spacing: -0.02em; display: flex; align-items: center; gap: 0.4rem; }
    .nav-logo img { image-rendering: pixelated; }
    .nav-logo .oxi { color: var(--accent); }
    .nav-links { display: flex; gap: 1.5rem; list-style: none; align-items: center; }
    .nav-links a { color: var(--text-muted); text-decoration: none; font-size: 0.85rem; font-weight: 500; transition: color 0.15s; }
    .nav-links a:hover { color: var(--text); }
    .nav-links a.active { color: var(--accent); }

    /* TOC */
    .toc { background: var(--bg-alt); border: 1px solid var(--border); border-radius: 10px; padding: 1.25rem 1.5rem; margin-bottom: 3rem; }
    .toc-title { font-family: var(--mono); font-size: 0.75rem; font-weight: 700; text-transform: uppercase; letter-spacing: 0.08em; color: var(--text-light); margin-bottom: 0.5rem; }
    .toc ul { list-style: none; display: flex; flex-wrap: wrap; gap: 0.5rem; }
    .toc a { display: inline-block; padding: 0.3rem 0.9rem; background: var(--surface); border: 1px solid var(--border); border-radius: 6px; color: var(--text); text-decoration: none; font-size: 0.85rem; font-weight: 600; transition: border-color 0.15s; }
    .toc a:hover { border-color: var(--accent); color: var(--accent); }

    /* PAGE LAYOUT */
    .page-header { padding: 4rem 2rem 2rem; max-width: var(--max-w); margin: 0 auto; }
    .page-header h1 { font-size: 2.5rem; font-weight: 800; letter-spacing: -0.03em; margin-bottom: 0.5rem; }
    .page-header p { color: var(--text-muted); font-size: 1.1rem; }
    .content { max-width: var(--max-w); margin: 0 auto; padding: 0 2rem 4rem; }

    /* CODE */
    pre { background: var(--code-bg); border-radius: 8px; padding: 1rem 1.25rem; overflow-x: auto; font-family: var(--mono); font-size: 0.8rem; line-height: 1.7; color: var(--code-text); margin: 0.75rem 0 1rem; }
    code { font-family: var(--mono); font-size: 0.85em; background: var(--bg-alt); padding: 0.15em 0.4em; border-radius: 4px; }
    pre code { background: none; padding: 0; }

    /* COMPONENTS */
    .note { background: rgba(14,165,233,0.06); border-left: 3px solid var(--accent); padding: 0.75rem 1rem; border-radius: 0 6px 6px 0; margin: 1rem 0; font-size: 0.85rem; color: var(--text); }
    .note strong { color: var(--accent); }
    .config-block { margin: 1rem 0; }
    .config-label { font-family: var(--mono); font-size: 0.7rem; color: var(--text-light); margin-bottom: 0.25rem; }

    /* LISTS */
    ol { padding-left: 1.5rem; margin-bottom: 1rem; }
    ol li { margin-bottom: 0.5rem; font-size: 0.9rem; color: var(--text); }
    ol li strong { color: var(--text); }

    /* FOOTER */
    footer { border-top: 1px solid var(--border); padding: 2rem; text-align: center; }
    .footer-inner { max-width: 1120px; margin: 0 auto; display: flex; align-items: center; justify-content: space-between; }
    .footer-links { display: flex; gap: 1.5rem; }
    .footer-links a { color: var(--text-muted); text-decoration: none; font-size: 0.8rem; }
    .footer-links a:hover { color: var(--text); }
    .footer-copy { color: var(--text-light); font-size: 0.75rem; }

    /* RESPONSIVE */
    @media (max-width: 768px) {
      .nav-links { gap: 1rem; }
      .page-header h1 { font-size: 1.75rem; }
      .toc ul { flex-direction: column; }
      .footer-inner { flex-direction: column; gap: 1rem; }
    }

    /* PAGE-SPECIFIC CSS */

    .cfg-section { margin-bottom: 3.5rem; scroll-margin-top: 80px; }
    .cfg-section h2 { font-size: 1.6rem; font-weight: 700; letter-spacing: -0.02em; margin-bottom: 0.5rem; padding-bottom: 0.75rem; border-bottom: 2px solid var(--border); }
    .cfg-section h3 { font-size: 1.1rem; font-weight: 600; margin-top: 1.5rem; margin-bottom: 0.5rem; }
    .cfg-section p { color: var(--text-muted); font-size: 0.9rem; margin-bottom: 0.75rem; }
    .cfg-section a { color: var(--accent); text-decoration: none; }
    .cfg-section a:hover { text-decoration: underline; }
    .cfg-table { width: 100%; border-collapse: collapse; margin: 0.75rem 0 1.5rem; font-size: 0.85rem; }
    .cfg-table th { text-align: left; font-family: var(--mono); font-size: 0.75rem; color: var(--text-light); text-transform: uppercase; letter-spacing: 0.08em; padding: 0.5rem 0.75rem; border-bottom: 2px solid var(--border); }
    .cfg-table td { padding: 0.5rem 0.75rem; border-bottom: 1px solid var(--border); vertical-align: top; }
    .cfg-table td:first-child { font-family: var(--mono); font-size: 0.8rem; color: var(--accent); white-space: nowrap; }
    .cfg-table td:last-child { color: var(--text-muted); }
    .flow-diagram { display: flex; align-items: center; gap: 0.5rem; flex-wrap: wrap; margin: 1rem 0 1.5rem; font-size: 0.85rem; }
    .flow-step { background: var(--bg-alt); border: 1px solid var(--border); border-radius: 6px; padding: 0.4rem 0.8rem; font-weight: 600; color: var(--text); }
    .flow-arrow { color: var(--text-light); font-size: 1.1rem; }
    .config-label { margin-top: 0.5rem; }
    ul.plain { list-style: disc; padding-left: 1.5rem; margin-bottom: 0.75rem; }
    ul.plain li { margin-bottom: 0.25rem; font-size: 0.88rem; color: var(--text-muted); }

  </style>
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@400;500;600;700&family=IBM+Plex+Sans:wght@400;500;600;700;800&display=swap" rel="stylesheet">
</head>
<body>

<nav>
  <div class="nav-inner">
    <a href="index.html" class="nav-logo"><img src="oxicrab.png" alt="" width="28" height="28"><span class="oxi">oxi</span>crab</a>
    <ul class="nav-links">
      <li><a href="index.html" >Home</a></li>
      <li><a href="config.html" class="active">Config</a></li>
      <li><a href="channels.html" >Channels</a></li>
      <li><a href="tools.html" >Tools</a></li>
      <li><a href="workspace.html" >Workspace</a></li>
      <li><a href="deploy.html" >Deploy</a></li>
      <li><a href="cli.html" >CLI</a></li>
      <li><a href="https://github.com/oxicrab/oxicrab">GitHub</a></li>
    </ul>
  </div>
</nav>

<div class="page-header">
    <h1>Configuration</h1>
    <p>Complete reference for <code>~/.oxicrab/config.json</code> (or <code>$OXICRAB_HOME/config.json</code>). Uses camelCase keys in JSON.</p>
</div>

<div class="content">

    <div class="toc">
        <div class="toc-title">Sections</div>
        <ul>
            <li><a href="#models">Models</a></li>
            <li><a href="#credentials">Credentials</a></li>
            <li><a href="#agent-defaults">Agent Defaults</a></li>
            <li><a href="#cost-guard">Cost Guard</a></li>
            <li><a href="#circuit-breaker">Circuit Breaker</a></li>
            <li><a href="#cognitive-routines">Cognitive Routines</a></li>
            <li><a href="#exfiltration-guard">Exfiltration Guard</a></li>
            <li><a href="#prompt-guard">Prompt Guard</a></li>
            <li><a href="#gateway">Gateway</a></li>
            <li><a href="#sandbox">Sandbox</a></li>
            <li><a href="#channels">Channels</a></li>
            <li><a href="#logging">Logging</a></li>
        </ul>
    </div>

    <!-- MODELS -->
    <div id="models" class="cfg-section">
        <h2>Model Routing</h2>
        <p>oxicrab uses a 3-tier resolution strategy to determine which LLM provider handles a model:</p>
        <ol>
            <li><strong>Explicit provider</strong> &mdash; <code>"provider": "anthropic"</code> in config or <code>--provider anthropic</code> on CLI</li>
            <li><strong>Prefix notation</strong> &mdash; <code>"model": "groq/llama-3.1-70b"</code> (provider before <code>/</code>, stripped before API call)</li>
            <li><strong>Auto-detection</strong> &mdash; Known model name prefixes: <code>claude-*</code> &rarr; Anthropic, <code>gpt-*</code>/<code>o1</code>/<code>o3</code> &rarr; OpenAI, <code>gemini-*</code> &rarr; Gemini, <code>deepseek-*</code> &rarr; DeepSeek</li>
        </ol>

        <h3 id="routing-examples">Routing Resolution Table</h3>
        <table class="cfg-table">
            <tr><th>Model value</th><th>Provider field</th><th>Resolved provider</th><th>API model sent</th></tr>
            <tr><td><code>claude-sonnet-4-5-20250929</code></td><td>(empty)</td><td>anthropic (auto)</td><td><code>claude-sonnet-4-5-20250929</code></td></tr>
            <tr><td><code>anthropic/claude-opus-4-6</code></td><td>(empty)</td><td>anthropic (prefix)</td><td><code>claude-opus-4-6</code></td></tr>
            <tr><td><code>groq/llama-3.1-70b</code></td><td>(empty)</td><td>groq (prefix)</td><td><code>llama-3.1-70b</code></td></tr>
            <tr><td><code>ollama/qwen3-coder:30b</code></td><td>(empty)</td><td>ollama (prefix)</td><td><code>qwen3-coder:30b</code></td></tr>
            <tr><td><code>my-fine-tune-v2</code></td><td><code>anthropic</code></td><td>anthropic (explicit)</td><td><code>my-fine-tune-v2</code></td></tr>
            <tr><td><code>meta-llama/Llama-3.3-70B</code></td><td><code>ollama</code></td><td>ollama (explicit)</td><td><code>meta-llama/Llama-3.3-70B</code></td></tr>
            <tr><td><code>deepseek-chat</code></td><td>(empty)</td><td>deepseek (auto)</td><td><code>deepseek-chat</code></td></tr>
        </table>

        <h3 id="api-key-models">API Key Models</h3>
        <p>Set the model and provide the corresponding API key. The provider is auto-detected from the model name:</p>
        <pre><code>{
  "agents": {
    "defaults": {
      "model": "claude-sonnet-4-5-20250929"
    }
  },
  "providers": {
    "anthropic": {
      "apiKey": "sk-ant-api03-..."
    }
  }
}</code></pre>

        <p>Available API key models:</p>
        <ul class="plain">
            <li><strong>claude-sonnet-4-5-20250929</strong> (Anthropic) &mdash; recommended, best balance</li>
            <li><strong>claude-haiku-4-5-20251001</strong> (Anthropic) &mdash; fastest</li>
            <li><strong>claude-opus-4-5-20251101</strong> (Anthropic) &mdash; most capable</li>
            <li><strong>gpt-4</strong>, <strong>gpt-3.5-turbo</strong> (OpenAI)</li>
            <li><strong>gemini-pro</strong> (Google)</li>
        </ul>

        <p><strong>Prompt caching:</strong> Anthropic providers automatically use <code>cache_control</code> on system messages and tool definitions, enabling up to 90% input token cost reduction for repeated content (5-minute TTL).</p>

        <h3 id="explicit-provider">Explicit Provider Override</h3>
        <p>For custom or fine-tuned models whose names don't match a known pattern, set the <code>provider</code> field explicitly:</p>
        <pre><code>{
  "agents": {
    "defaults": {
      "model": "my-custom-fine-tune",
      "provider": "anthropic"
    }
  }
}</code></pre>
        <p>This is also useful for models with slashes that aren't provider prefixes (e.g. <code>meta-llama/Llama-3.3-70B</code> with <code>"provider": "ollama"</code>). The <code>--provider</code> CLI flag provides the same override per-invocation.</p>

        <h3 id="supported-providers">Supported Providers</h3>
        <p>The following providers are supported. Use prefix notation (e.g. <code>groq/llama-3.1-70b</code>) or the explicit <code>provider</code> field to route to them:</p>
        <pre><code>{
  "agents": {
    "defaults": {
      "model": "deepseek-chat"
    }
  },
  "providers": {
    "deepseek": {
      "apiKey": "sk-..."
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Provider</th><th>Default Base URL</th><th>API Key Required</th></tr>
            <tr><td>Anthropic</td><td>https://api.anthropic.com/v1/messages</td><td>Yes (or OAuth)</td></tr>
            <tr><td>OpenAI</td><td>https://api.openai.com/v1/chat/completions</td><td>Yes</td></tr>
            <tr><td>Gemini</td><td>https://generativelanguage.googleapis.com/v1beta</td><td>Yes</td></tr>
            <tr><td>OpenRouter</td><td>https://openrouter.ai/api/v1/chat/completions</td><td>Yes</td></tr>
            <tr><td>DeepSeek</td><td>https://api.deepseek.com/v1/chat/completions</td><td>Yes</td></tr>
            <tr><td>Groq</td><td>https://api.groq.com/openai/v1/chat/completions</td><td>Yes</td></tr>
            <tr><td>Moonshot</td><td>https://api.moonshot.cn/v1/chat/completions</td><td>Yes</td></tr>
            <tr><td>Zhipu</td><td>https://open.bigmodel.cn/api/paas/v4/chat/completions</td><td>Yes</td></tr>
            <tr><td>DashScope</td><td>https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions</td><td>Yes</td></tr>
            <tr><td>vLLM</td><td>http://localhost:8000/v1/chat/completions</td><td>No</td></tr>
            <tr><td>Ollama</td><td>http://localhost:11434/v1/chat/completions</td><td>No</td></tr>
        </table>

        <p>Local providers (Ollama and vLLM) do not require an API key. Use the <code>provider/model</code> prefix format to route to them &mdash; the prefix is stripped before sending to the API (e.g. <code>ollama/qwen3-coder:30b</code> sends <code>qwen3-coder:30b</code> to the Ollama API).</p>

        <h3 id="prompt-guided-tools">Prompt-Guided Tool Calling</h3>
        <p>Local models often ignore native JSON tool schemas, responding with plain text instead of structured tool calls. Enable <code>promptGuidedTools</code> on the provider to work around this:</p>
        <pre><code>{
  "providers": {
    "ollama": {
      "promptGuidedTools": true
    }
  }
}</code></pre>

        <p>When enabled, the <code>PromptGuidedToolsProvider</code> wrapper:</p>
        <ul class="plain">
            <li>Injects tool definitions as structured text into the system prompt</li>
            <li>Strips native <code>tools</code>/<code>tool_choice</code> from the API request</li>
            <li>Parses <code>&lt;tool_call&gt;</code> XML blocks from the model's text response into tool calls</li>
            <li>Rewrites conversation history so tool results work without native tool support</li>
        </ul>

        <p>This works with both direct local models and the <a href="#local-model-fallback">local model fallback</a> configuration. Currently supported for Ollama and vLLM providers.</p>

        <p>To override the default endpoint, set <code>apiBase</code> on the provider:</p>
        <pre><code>{
  "providers": {
    "vllm": {
      "apiKey": "token-abc123",
      "apiBase": "http://my-server:8080/v1/chat/completions"
    }
  }
}</code></pre>

        <h3 id="custom-headers">Custom Headers</h3>
        <p>Inject custom HTTP headers into every request for an OpenAI-compatible provider. Useful for authentication proxies, routing, or API gateways:</p>
        <pre><code>{
  "providers": {
    "openrouter": {
      "apiKey": "sk-...",
      "headers": {
        "X-Custom-Header": "value",
        "HTTP-Referer": "https://myapp.example.com"
      }
    }
  }
}</code></pre>
        <p>Headers are merged into every chat and warmup request alongside the standard <code>Authorization</code> and <code>Content-Type</code> headers.</p>

        <h3 id="local-model-fallback">Local Model Fallback</h3>
        <p>Configure a local model (e.g. Ollama) as a fallback. The cloud model remains primary &mdash; the local model is only used if the cloud provider fails or returns malformed tool calls:</p>
        <pre><code>{
  "agents": {
    "defaults": {
      "model": "claude-sonnet-4-5-20250929",
      "localModel": "ollama/qwen3-coder:30b"
    }
  },
  "providers": {
    "anthropic": {
      "apiKey": "sk-ant-api03-..."
    }
  }
}</code></pre>
        <p>When <code>localModel</code> is set, each LLM call tries the cloud model first. If it returns an error (network failure, rate limit) or malformed tool calls (empty name, non-object arguments), the request is automatically retried against the local model.</p>

        <h3 id="oauth-models">OAuth Models</h3>
        <p>Anthropic OAuth is attempted when the provider resolves to <code>anthropic</code> &mdash; via <code>anthropic/</code> prefix, <code>"provider": "anthropic"</code>, or auto-detection of <code>claude-*</code> models:</p>
        <ul class="plain">
            <li><strong>anthropic/claude-opus-4-5</strong></li>
            <li><strong>anthropic/claude-opus-4-6</strong></li>
        </ul>

        <p>For OAuth models, either install <a href="https://github.com/anthropics/claude-cli">Claude CLI</a> (auto-detected) or configure credentials manually:</p>
        <pre><code>{
  "providers": {
    "anthropicOAuth": {
      "enabled": true,
      "autoDetect": true,
      "credentialsPath": "~/.anthropic/credentials.json"
    }
  }
}</code></pre>
    </div>

    <!-- CREDENTIALS -->
    <div id="credentials" class="cfg-section">
        <h2>Credentials</h2>
        <p>Oxicrab supports multiple credential backends. Each layer only fills fields that are still empty, so higher-priority sources always win.</p>

        <h3 id="resolution-order">Resolution Order</h3>
        <div class="flow-diagram">
            <span class="flow-step">Environment variables</span>
            <span class="flow-arrow">&rarr;</span>
            <span class="flow-step">Credential helper</span>
            <span class="flow-arrow">&rarr;</span>
            <span class="flow-step">OS keyring</span>
            <span class="flow-arrow">&rarr;</span>
            <span class="flow-step">config.json</span>
        </div>
        <p>Use <code>oxicrab credentials list</code> to see where each credential comes from.</p>

        <h3 id="os-keyring">OS Keyring</h3>
        <p>Credentials can be stored in the OS keychain (macOS Keychain, GNOME Keyring, Windows Credential Manager) via the <code>keyring-store</code> feature (default-on). Containers should use <code>OXICRAB_*</code> env vars instead. See <a href="cli.html#credentials">CLI Reference &rarr; credentials</a> for keyring management commands.</p>

        <h3 id="credential-helper">Credential Helper</h3>
        <p>External programs (1Password, Bitwarden, custom scripts) can supply credentials at startup. Configure under the top-level <code>credentialHelper</code> key.</p>

        <h3>1Password (desktop)</h3>
        <pre><code>{
  "credentialHelper": {
    "command": "op",
    "args": ["item", "get", "oxicrab", "--format", "json"],
    "format": "1password"
  }
}</code></pre>

        <h3>1Password (CI / containers)</h3>
        <pre><code>{
  "credentialHelper": {
    "command": "op",
    "args": ["read", "-"],
    "format": "json"
  }
}</code></pre>

        <h3>Bitwarden</h3>
        <pre><code>{
  "credentialHelper": {
    "command": "bw",
    "args": ["get", "item", "oxicrab"],
    "format": "bitwarden"
  }
}</code></pre>

        <h3>Custom script</h3>
        <pre><code>{
  "credentialHelper": {
    "command": "/path/to/my-script.sh",
    "args": [],
    "format": "json"
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Format</th><th>Description</th></tr>
            <tr><td>1password</td><td>Parses 1Password <code>op item get</code> JSON output (fields array)</td></tr>
            <tr><td>bitwarden</td><td>Parses Bitwarden <code>bw get item</code> JSON output (fields array)</td></tr>
            <tr><td>json</td><td>Expects a flat JSON object: <code>{"anthropic-api-key": "sk-...", ...}</code></td></tr>
            <tr><td>line</td><td>Expects <code>key=value</code> pairs, one per line</td></tr>
        </table>

        <h3 id="environment-variables">Environment Variables</h3>
        <p>All 28 credential slots can be set via environment variables. Recommended for containers and CI.</p>

        <h3>Providers</h3>
        <table class="cfg-table">
            <tr><th>Variable</th><th>Config Field</th></tr>
            <tr><td>OXICRAB_ANTHROPIC_API_KEY</td><td>providers.anthropic.apiKey</td></tr>
            <tr><td>OXICRAB_OPENAI_API_KEY</td><td>providers.openai.apiKey</td></tr>
            <tr><td>OXICRAB_OPENROUTER_API_KEY</td><td>providers.openrouter.apiKey</td></tr>
            <tr><td>OXICRAB_GEMINI_API_KEY</td><td>providers.gemini.apiKey</td></tr>
            <tr><td>OXICRAB_DEEPSEEK_API_KEY</td><td>providers.deepseek.apiKey</td></tr>
            <tr><td>OXICRAB_GROQ_API_KEY</td><td>providers.groq.apiKey</td></tr>
            <tr><td>OXICRAB_MOONSHOT_API_KEY</td><td>providers.moonshot.apiKey</td></tr>
            <tr><td>OXICRAB_ZHIPU_API_KEY</td><td>providers.zhipu.apiKey</td></tr>
            <tr><td>OXICRAB_DASHSCOPE_API_KEY</td><td>providers.dashscope.apiKey</td></tr>
            <tr><td>OXICRAB_VLLM_API_KEY</td><td>providers.vllm.apiKey</td></tr>
            <tr><td>OXICRAB_OLLAMA_API_KEY</td><td>providers.ollama.apiKey</td></tr>
        </table>

        <h3>OAuth</h3>
        <table class="cfg-table">
            <tr><th>Variable</th><th>Config Field</th></tr>
            <tr><td>OXICRAB_ANTHROPIC_OAUTH_ACCESS</td><td>providers.anthropicOAuth.accessToken</td></tr>
            <tr><td>OXICRAB_ANTHROPIC_OAUTH_REFRESH</td><td>providers.anthropicOAuth.refreshToken</td></tr>
        </table>

        <h3>Channels</h3>
        <table class="cfg-table">
            <tr><th>Variable</th><th>Config Field</th></tr>
            <tr><td>OXICRAB_TELEGRAM_TOKEN</td><td>channels.telegram.token</td></tr>
            <tr><td>OXICRAB_DISCORD_TOKEN</td><td>channels.discord.token</td></tr>
            <tr><td>OXICRAB_SLACK_BOT_TOKEN</td><td>channels.slack.botToken</td></tr>
            <tr><td>OXICRAB_SLACK_APP_TOKEN</td><td>channels.slack.appToken</td></tr>
            <tr><td>OXICRAB_TWILIO_ACCOUNT_SID</td><td>channels.twilio.accountSid</td></tr>
            <tr><td>OXICRAB_TWILIO_AUTH_TOKEN</td><td>channels.twilio.authToken</td></tr>
        </table>

        <h3>Tools</h3>
        <table class="cfg-table">
            <tr><th>Variable</th><th>Config Field</th></tr>
            <tr><td>OXICRAB_GITHUB_TOKEN</td><td>tools.github.token</td></tr>
            <tr><td>OXICRAB_WEATHER_API_KEY</td><td>tools.weather.apiKey</td></tr>
            <tr><td>OXICRAB_TODOIST_TOKEN</td><td>tools.todoist.token</td></tr>
            <tr><td>OXICRAB_WEB_SEARCH_API_KEY</td><td>tools.web.search.apiKey</td></tr>
            <tr><td>OXICRAB_GOOGLE_CLIENT_SECRET</td><td>tools.google.clientSecret</td></tr>
            <tr><td>OXICRAB_OBSIDIAN_API_KEY</td><td>tools.obsidian.apiKey</td></tr>
            <tr><td>OXICRAB_MEDIA_RADARR_API_KEY</td><td>tools.media.radarr.apiKey</td></tr>
            <tr><td>OXICRAB_MEDIA_SONARR_API_KEY</td><td>tools.media.sonarr.apiKey</td></tr>
        </table>

        <h3>Voice</h3>
        <table class="cfg-table">
            <tr><th>Variable</th><th>Config Field</th></tr>
            <tr><td>OXICRAB_TRANSCRIPTION_API_KEY</td><td>voice.transcription.apiKey</td></tr>
        </table>
    </div>

    <!-- AGENT DEFAULTS -->
    <div id="agent-defaults" class="cfg-section">
        <h2>Agent Defaults</h2>
        <p>All agent defaults live under <code>agents.defaults</code> in config.json.</p>

        <h3>Top-level Fields</h3>
        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>workspace</td><td>string</td><td>~/.oxicrab/workspace</td><td>Path to workspace directory</td></tr>
            <tr><td>model</td><td>string</td><td>claude-sonnet-4-5-20250929</td><td>Default LLM model</td></tr>
            <tr><td>maxTokens</td><td>u32</td><td>8192</td><td>Max tokens per LLM response</td></tr>
            <tr><td>temperature</td><td>f32</td><td>0.7</td><td>LLM sampling temperature (0.0&ndash;2.0)</td></tr>
            <tr><td>maxToolIterations</td><td>usize</td><td>20</td><td>Max agent loop iterations per turn</td></tr>
            <tr><td>sessionTtlDays</td><td>u32</td><td>30</td><td>Days before inactive sessions are pruned</td></tr>
            <tr><td>memoryIndexerInterval</td><td>u64</td><td>300</td><td>Seconds between memory indexer runs</td></tr>
            <tr><td>mediaTtlDays</td><td>u32</td><td>7</td><td>Days before cached media files are cleaned up</td></tr>
            <tr><td>maxConcurrentSubagents</td><td>usize</td><td>5</td><td>Max simultaneous background subagents</td></tr>
            <tr><td>localModel</td><td>string?</td><td>null</td><td>Fallback model for cloud failures (see <a href="#local-model-fallback">Local Model Fallback</a>)</td></tr>
        </table>

        <h3>Compaction</h3>
        <p>Config path: <code>agents.defaults.compaction</code></p>
        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>true</td><td>Enable automatic context compaction</td></tr>
            <tr><td>thresholdTokens</td><td>u32</td><td>40000</td><td>Token count that triggers compaction</td></tr>
            <tr><td>keepRecent</td><td>usize</td><td>10</td><td>Number of recent messages to preserve verbatim</td></tr>
            <tr><td>extractionEnabled</td><td>bool</td><td>true</td><td>Extract facts to memory during compaction</td></tr>
            <tr><td>model</td><td>string?</td><td>null</td><td>Override model for compaction (uses default if null)</td></tr>
            <tr><td>preFlushEnabled</td><td>bool</td><td>false</td><td>Flush pending memory notes to disk before compaction runs, ensuring extracted facts survive context truncation</td></tr>
            <tr><td>checkpoint</td><td>object</td><td>see below</td><td>Periodic checkpoint configuration</td></tr>
        </table>

        <h3>Checkpoint</h3>
        <p>Config path: <code>agents.defaults.compaction.checkpoint</code></p>
        <p>Periodic checkpoints snapshot conversation state during long agent runs, providing recovery context if compaction occurs.</p>
        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>false</td><td>Enable periodic checkpoints</td></tr>
            <tr><td>intervalIterations</td><td>u32</td><td>10</td><td>Iterations between checkpoints</td></tr>
        </table>

        <h3>Daemon</h3>
        <p>Config path: <code>agents.defaults.daemon</code>. The daemon runs periodic heartbeat check-ins using the agent loop.</p>
        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>true</td><td>Enable heartbeat/daemon service</td></tr>
            <tr><td>interval</td><td>u64</td><td>300</td><td>Seconds between daemon check-ins</td></tr>
            <tr><td>executionModel</td><td>string?</td><td>null</td><td>Override model for daemon runs (e.g. use a cheaper model for heartbeats). Uses the default agent model when null.</td></tr>
            <tr><td>executionProvider</td><td>string?</td><td>null</td><td>Override provider for daemon runs. <em>Not yet supported</em> &mdash; the default provider is always used. A warning is logged if set.</td></tr>
            <tr><td>strategyFile</td><td>string</td><td>HEARTBEAT.md</td><td>Workspace file defining daemon behavior</td></tr>
            <tr><td>maxIterations</td><td>usize</td><td>25</td><td>Max agent loop iterations per daemon run (overrides the agent-level <code>maxToolIterations</code>)</td></tr>
        </table>

        <h3>Memory</h3>
        <p>Config path: <code>agents.defaults.memory</code></p>
        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>archiveAfterDays</td><td>u32</td><td>30</td><td>Days before notes are archived</td></tr>
            <tr><td>purgeAfterDays</td><td>u32</td><td>90</td><td>Days before archived notes are purged (must be &gt; archiveAfterDays)</td></tr>
            <tr><td>embeddingsEnabled</td><td>bool</td><td>false</td><td>Enable hybrid vector+keyword search via local ONNX embeddings</td></tr>
            <tr><td>embeddingsModel</td><td>string</td><td>BAAI/bge-small-en-v1.5</td><td>Embedding model for vector search</td></tr>
            <tr><td>hybridWeight</td><td>f32</td><td>0.5</td><td>Blend weight: 0.0 = keyword only, 1.0 = vector only</td></tr>
            <tr><td>searchFusionStrategy</td><td>string</td><td>"weighted_score"</td><td>Fusion strategy for hybrid search: <code>"weighted_score"</code> (linear blend) or <code>"rrf"</code> (reciprocal rank fusion)</td></tr>
            <tr><td>rrfK</td><td>u32</td><td>60</td><td>RRF smoothing constant (only used when fusion strategy is <code>"rrf"</code>)</td></tr>
            <tr><td>embeddingCacheSize</td><td>usize</td><td>10000</td><td>LRU cache size for embedding query results</td></tr>
        </table>

        <p>When embeddings are enabled, the system prompt context injection automatically uses hybrid search (combined keyword + vector similarity) instead of keyword-only search. Missing embeddings are back-filled automatically during indexing.</p>

        <p><strong>Utility-based archiving:</strong> Notes between <code>archiveAfterDays / 2</code> and <code>archiveAfterDays</code> are archived early if they have zero search hits. Notes that are frequently retrieved are kept longer. Use <code>oxicrab stats search</code> to see hit counts.</p>
    </div>

    <!-- COST GUARD -->
    <div id="cost-guard" class="cfg-section">
        <h2>Cost Guard</h2>
        <p>Pre-flight budget gating and post-flight cost tracking. Blocks LLM calls if the daily budget is exceeded or the hourly rate limit is hit. Daily budget resets at midnight UTC.</p>

        <p>Config path: <code>agents.defaults.costGuard</code></p>
        <pre><code>{
  "agents": {
    "defaults": {
      "costGuard": {
        "dailyBudgetCents": 500,
        "maxActionsPerHour": 100,
        "modelCosts": {
          "claude-sonnet": {
            "inputPerMillion": 3.0,
            "outputPerMillion": 15.0
          }
        }
      }
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>dailyBudgetCents</td><td>u64?</td><td>null</td><td>Maximum daily spend in cents (null = unlimited)</td></tr>
            <tr><td>maxActionsPerHour</td><td>u64?</td><td>null</td><td>Maximum LLM calls per hour (null = unlimited)</td></tr>
            <tr><td>modelCosts</td><td>object</td><td>{}</td><td>Per-model cost overrides keyed by model name prefix</td></tr>
        </table>

        <p>Each entry in <code>modelCosts</code> has:</p>
        <ul class="plain">
            <li><strong>inputPerMillion</strong> &mdash; cost in dollars per million input tokens</li>
            <li><strong>outputPerMillion</strong> &mdash; cost in dollars per million output tokens</li>
        </ul>

        <p>Embedded pricing data covers 50+ models. Config overrides take precedence for any model name prefix match.</p>

        <h3>Prompt Cache-Aware Pricing</h3>
        <p>For Anthropic providers, prompt caching tokens are priced differently:</p>
        <ul class="plain">
            <li><strong>Cache read tokens</strong> &mdash; billed at <strong>10%</strong> of the input token rate (90% discount)</li>
            <li><strong>Cache creation tokens</strong> &mdash; billed at <strong>125%</strong> of the input token rate (25% surcharge)</li>
        </ul>
        <p>This is applied automatically when the Anthropic API reports <code>cache_read_input_tokens</code> and <code>cache_creation_input_tokens</code> in the response usage.</p>

        <h3>Cost Persistence</h3>
        <p>All LLM call costs are persisted to the memory SQLite database (<code>memory/memory.sqlite3</code>). This means:</p>
        <ul class="plain">
            <li><strong>Daily budget survives restarts</strong> &mdash; accumulated cost is restored from the database on startup</li>
            <li><strong>Historical data</strong> &mdash; query past costs via <code>oxicrab stats costs</code> and <code>oxicrab stats today</code></li>
            <li><strong>Per-call breakdown</strong> &mdash; model, input/output tokens, cache tokens, cost in cents, and caller</li>
        </ul>
    </div>

    <!-- CIRCUIT BREAKER -->
    <div id="circuit-breaker" class="cfg-section">
        <h2>Circuit Breaker</h2>
        <p>Wraps the LLM provider with a three-state circuit breaker that trips only on transient errors, preventing cascading failures during outages.</p>

        <p>Config path: <code>providers.circuitBreaker</code></p>
        <pre><code>{
  "providers": {
    "circuitBreaker": {
      "enabled": true,
      "failureThreshold": 5,
      "recoveryTimeoutSecs": 60,
      "halfOpenProbes": 2
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>false</td><td>Enable circuit breaker wrapping</td></tr>
            <tr><td>failureThreshold</td><td>u32</td><td>5</td><td>Consecutive transient failures before opening</td></tr>
            <tr><td>recoveryTimeoutSecs</td><td>u64</td><td>60</td><td>Seconds to wait in Open state before probing</td></tr>
            <tr><td>halfOpenProbes</td><td>u32</td><td>2</td><td>Successful probes needed to close again</td></tr>
        </table>

        <h3>States</h3>
        <ul class="plain">
            <li><strong>Closed</strong> &mdash; normal operation, requests pass through</li>
            <li><strong>Open</strong> &mdash; all requests rejected immediately (after <code>failureThreshold</code> consecutive transient failures)</li>
            <li><strong>HalfOpen</strong> &mdash; allows <code>halfOpenProbes</code> test requests after <code>recoveryTimeoutSecs</code></li>
        </ul>

        <h3>Transient vs Non-Transient Errors</h3>
        <p><strong>Transient</strong> (trip the breaker): HTTP 429, 5xx, timeout, connection refused/reset.</p>
        <p><strong>Non-transient</strong> (do not trip): auth errors, invalid API key, permission denied, context length exceeded.</p>
    </div>

    <!-- COGNITIVE ROUTINES -->
    <div id="cognitive-routines" class="cfg-section">
        <h2>Cognitive Routines</h2>
        <p>Escalating pressure signals that nudge the LLM to self-checkpoint its progress during long tool-heavy agent loop runs. Prevents loss of context when compaction discards older messages.</p>

        <p>Config path: <code>agents.defaults.cognitive</code></p>
        <pre><code>{
  "agents": {
    "defaults": {
      "cognitive": {
        "enabled": true,
        "gentleThreshold": 12,
        "firmThreshold": 20,
        "urgentThreshold": 30,
        "recentToolsWindow": 10
      }
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>false</td><td>Enable cognitive checkpoint pressure signals</td></tr>
            <tr><td>gentleThreshold</td><td>u32</td><td>12</td><td>Tool calls before a gentle hint to summarize progress</td></tr>
            <tr><td>firmThreshold</td><td>u32</td><td>20</td><td>Tool calls before a firm warning to write a checkpoint</td></tr>
            <tr><td>urgentThreshold</td><td>u32</td><td>30</td><td>Tool calls before an urgent demand to stop and summarize</td></tr>
            <tr><td>recentToolsWindow</td><td>usize</td><td>10</td><td>Rolling window size for tracking recent tool names</td></tr>
        </table>

        <h3>Pressure Levels</h3>
        <ul class="plain">
            <li><strong>Gentle</strong> (hint) &mdash; suggests briefly noting progress</li>
            <li><strong>Firm</strong> (warning) &mdash; asks the LLM to pause and write a checkpoint</li>
            <li><strong>Urgent</strong> (STOP) &mdash; demands an immediate detailed progress summary</li>
        </ul>
        <p>Each level fires only once per checkpoint cycle. Counters reset when a periodic checkpoint fires.</p>
    </div>

    <!-- EXFILTRATION GUARD -->
    <div id="exfiltration-guard" class="cfg-section">
        <h2>Exfiltration Guard</h2>
        <p>Hides outbound-capable tools (http, web_fetch, browser) from the LLM when enabled, preventing prompt-injected data exfiltration. Tools are filtered from the tool definitions sent to the LLM and blocked at dispatch time.</p>

        <p>Config path: <code>tools.exfiltrationGuard</code></p>
        <pre><code>{
  "tools": {
    "exfiltrationGuard": {
      "enabled": true,
      "blockedTools": ["http", "web_fetch", "browser"]
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>false</td><td>Enable exfiltration guard</td></tr>
            <tr><td>blockedTools</td><td>string[]</td><td>["http", "web_fetch", "browser"]</td><td>Tool names to hide from LLM and block at dispatch</td></tr>
        </table>
    </div>

    <!-- PROMPT GUARD -->
    <div id="prompt-guard" class="cfg-section">
        <h2>Prompt Guard</h2>
        <p>Regex-based prompt injection detection. Scans user messages before LLM processing and tool output after execution. Four pattern categories: role switching, instruction override, secret extraction, and jailbreak patterns.</p>

        <p>Config path: <code>agents.defaults.promptGuard</code></p>
        <pre><code>{
  "agents": {
    "defaults": {
      "promptGuard": {
        "enabled": true,
        "action": "block"
      }
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>false</td><td>Enable prompt injection detection</td></tr>
            <tr><td>action</td><td>string</td><td>"warn"</td><td>"warn" (log and continue) or "block" (reject the message)</td></tr>
        </table>

        <h3>Detection Categories</h3>
        <ul class="plain">
            <li><strong>Role switching</strong> &mdash; attempts to change persona ("ignore previous instructions", "you are now...")</li>
            <li><strong>Instruction override</strong> &mdash; attempts to replace system prompts ("new instructions:", "override system...")</li>
            <li><strong>Secret extraction</strong> &mdash; attempts to extract system prompts ("show me your system prompt", "repeat your instructions")</li>
            <li><strong>Jailbreak</strong> &mdash; common jailbreak prefixes ("DAN mode", "developer mode", "jailbreak")</li>
        </ul>
        <p>User messages are scanned with the configured action. Tool output is always warn-only (tool output may legitimately contain these phrases).</p>
    </div>

    <!-- CONTEXT PROVIDERS -->
    <div id="context-providers" class="cfg-section">
        <h2>Context Providers</h2>
        <p>External shell commands that inject dynamic content into the system prompt each turn. Each provider runs its command, caches the output with a TTL, and appends it under a <code># Dynamic Context</code> header.</p>

        <p>Config path: <code>agents.defaults.contextProviders</code></p>
        <pre><code>{
  "agents": {
    "defaults": {
      "contextProviders": [
        {
          "name": "Git Status",
          "command": "git",
          "args": ["status", "--short"],
          "enabled": true,
          "timeout": 5,
          "ttl": 60,
          "requiresBins": ["git"],
          "requiresEnv": []
        }
      ]
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>name</td><td>string</td><td><em>required</em></td><td>Section header in the system prompt</td></tr>
            <tr><td>command</td><td>string</td><td><em>required</em></td><td>Executable to run</td></tr>
            <tr><td>args</td><td>string[]</td><td>[]</td><td>Command arguments</td></tr>
            <tr><td>enabled</td><td>bool</td><td>true</td><td>Enable or disable this provider</td></tr>
            <tr><td>timeout</td><td>u64</td><td>5</td><td>Execution timeout in seconds</td></tr>
            <tr><td>ttl</td><td>u64</td><td>300</td><td>Cache lifetime in seconds before re-executing</td></tr>
            <tr><td>requiresBins</td><td>string[]</td><td>[]</td><td>Required binaries (skipped if any missing)</td></tr>
            <tr><td>requiresEnv</td><td>string[]</td><td>[]</td><td>Required environment variables (skipped if any missing)</td></tr>
        </table>

        <p>Providers that fail, time out, or have missing dependencies are silently skipped &mdash; they never block the agent loop.</p>
    </div>

    <!-- GATEWAY -->
    <div id="gateway" class="cfg-section">
        <h2>Gateway</h2>
        <p>Controls the HTTP gateway server used by <code>oxicrab gateway</code>. Config path: <code>gateway</code></p>

        <pre><code>{
  "gateway": {
    "enabled": true,
    "host": "127.0.0.1",
    "port": 18790,
    "webhooks": {
      "github": {
        "enabled": true,
        "secret": "your-hmac-secret",
        "template": "GitHub {{action}} on {{repository.full_name}}: {{body}}",
        "targets": [{"channel": "slack", "chatId": "C12345"}],
        "agentTurn": true
      }
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>true</td><td>Enable or disable the HTTP gateway server</td></tr>
            <tr><td>host</td><td>string</td><td>127.0.0.1</td><td>Bind address for the gateway HTTP server</td></tr>
            <tr><td>port</td><td>u16</td><td>18790</td><td>Port for the gateway HTTP server</td></tr>
            <tr><td>webhooks</td><td>object</td><td>{}</td><td>Named webhook receivers (see below)</td></tr>
            <tr><td>a2a</td><td>object</td><td>{}</td><td>Agent-to-Agent protocol configuration (see below)</td></tr>
        </table>

        <h3>HTTP API Endpoints</h3>
        <table class="cfg-table">
            <tr><th>Endpoint</th><th>Method</th><th>Description</th></tr>
            <tr><td>/api/chat</td><td>POST</td><td>Send a message and receive the agent's response. Body: <code>{"message": "...", "session_id": "..."}</code></td></tr>
            <tr><td>/api/health</td><td>GET</td><td>Health check. Returns <code>{"status": "ok", "version": "..."}</code></td></tr>
            <tr><td>/api/webhook/{name}</td><td>POST</td><td>Receive a webhook from an external service (see webhook config below)</td></tr>
            <tr><td>/.well-known/agent.json</td><td>GET</td><td>A2A AgentCard (when A2A enabled)</td></tr>
            <tr><td>/a2a/tasks</td><td>POST</td><td>Submit an A2A task. Body: <code>{"message": "..."}</code></td></tr>
            <tr><td>/a2a/tasks/{id}</td><td>GET</td><td>Get A2A task status and result</td></tr>
        </table>

        <h3>Agent-to-Agent (A2A) Protocol</h3>
        <p>Google's A2A protocol for agent discovery and interoperability. When enabled, exposes an <code>AgentCard</code> at <code>/.well-known/agent.json</code> and a task lifecycle at <code>/a2a/tasks</code>.</p>
        <pre><code>{
  "gateway": {
    "a2a": {
      "enabled": true,
      "agentName": "My Agent",
      "agentDescription": "A helpful AI assistant"
    }
  }
}</code></pre>
        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>false</td><td>Enable A2A protocol endpoints</td></tr>
            <tr><td>agentName</td><td>string</td><td>"oxicrab"</td><td>Agent name in the AgentCard</td></tr>
            <tr><td>agentDescription</td><td>string</td><td>"AI assistant powered by oxicrab"</td><td>Agent description in the AgentCard</td></tr>
        </table>
        <p>Tasks are processed through the same agent loop as chat messages. The task lifecycle: <strong>submitted</strong> &rarr; <strong>working</strong> &rarr; <strong>completed</strong> (or <strong>failed</strong>). Poll <code>GET /a2a/tasks/{id}</code> to check status.</p>

        <h3>Webhook Configuration</h3>
        <p>Each entry in <code>webhooks</code> creates a receiver at <code>POST /api/webhook/{name}</code>. Payloads are validated with HMAC-SHA256 signature verification (constant-time comparison).</p>
        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>true</td><td>Enable or disable this webhook endpoint. Disabled webhooks return 404</td></tr>
            <tr><td>secret</td><td>string</td><td>&mdash;</td><td>HMAC-SHA256 secret for signature validation</td></tr>
            <tr><td>template</td><td>string</td><td>{{body}}</td><td>Message template. Use <code>{{key}}</code> for JSON payload fields, <code>{{body}}</code> for raw body</td></tr>
            <tr><td>targets</td><td>array</td><td>[]</td><td>Delivery targets: <code>[{"channel": "slack", "chatId": "C12345"}]</code></td></tr>
            <tr><td>agentTurn</td><td>bool</td><td>false</td><td>If true, routes through the agent loop before delivering to targets</td></tr>
        </table>
        <p>Signature headers checked: <code>X-Signature-256</code>, <code>X-Hub-Signature-256</code>, <code>X-Webhook-Signature</code>. Supports <code>sha256=</code> prefix (GitHub-style). Max payload: 1 MB.</p>

        <p>Set <code>host</code> to <code>"0.0.0.0"</code> to listen on all interfaces (required for Docker/container deployments). The Twilio channel uses this same gateway for its webhook listener.</p>
    </div>

    <!-- SANDBOX -->
    <div id="sandbox" class="cfg-section">
        <h2>Sandbox</h2>
        <p>Kernel-enforced filesystem and network restrictions applied to both shell commands (<code>tools.exec.sandbox</code>) and MCP server child processes (<code>tools.mcp.servers.*.sandbox</code>). On <strong>Linux</strong>, uses Landlock LSM. On <strong>macOS</strong>, uses Seatbelt (<code>sandbox_init</code>). Graceful no-op on unsupported platforms or older Linux kernels.</p>

        <pre><code>{
  "tools": {
    "exec": {
      "sandbox": {
        "enabled": true,
        "additionalReadPaths": ["/opt/data"],
        "additionalWritePaths": ["/home/user/output"],
        "blockNetwork": true
      }
    }
  }
}</code></pre>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>true</td><td>Enable kernel-level process sandboxing (Landlock on Linux, Seatbelt on macOS)</td></tr>
            <tr><td>additionalReadPaths</td><td>string[]</td><td>[]</td><td>Extra paths to grant read-only access (beyond <code>/usr</code>, <code>/lib</code>, <code>/lib64</code>, <code>/bin</code>, <code>/sbin</code>, <code>/etc</code>)</td></tr>
            <tr><td>additionalWritePaths</td><td>string[]</td><td>[]</td><td>Extra paths to grant read-write access (beyond workspace + <code>/tmp</code> + <code>/var/tmp</code>)</td></tr>
            <tr><td>blockNetwork</td><td>bool</td><td>true</td><td>Block all outbound TCP connections from shell commands</td></tr>
        </table>

        <p><strong>Linux (Landlock):</strong> Default read-only: <code>/usr</code>, <code>/lib</code>, <code>/lib64</code>, <code>/bin</code>, <code>/sbin</code>, <code>/etc</code>. Default read-write: workspace dir, <code>/tmp</code>, <code>/var/tmp</code>. Degrades gracefully on older kernels via BestEffort mode.</p>
        <p><strong>macOS (Seatbelt):</strong> Same default paths plus macOS-specific system paths (<code>/System</code>, <code>/Library</code>, <code>/opt/homebrew</code>, <code>/usr/local</code>) for read-only, and symlink targets (<code>/private/tmp</code>, <code>/private/var/folders</code>) for read-write. Also grants process execution, Mach IPC, and signal operations required for child processes.</p>
        <p>All other filesystem access and network connections are denied. Use <code>oxicrab doctor</code> to check sandbox availability on your system.</p>
    </div>

    <!-- CHANNELS -->
    <div id="channels" class="cfg-section">
        <h2>Channels</h2>
        <p>Per-channel configuration under <code>channels.{name}</code>. See <a href="channels.html">Channel Setup</a> for step-by-step guides. All channels share these common fields:</p>

        <table class="cfg-table">
            <tr><th>Field</th><th>Type</th><th>Default</th><th>Description</th></tr>
            <tr><td>enabled</td><td>bool</td><td>false</td><td>Enable this channel</td></tr>
            <tr><td>allowFrom</td><td>string[]</td><td>[]</td><td>Authorized sender IDs. Empty = deny-all. Use <code>["*"]</code> for open access.</td></tr>
            <tr><td>dmPolicy</td><td>string</td><td>"allowlist"</td><td>DM access policy: <code>"allowlist"</code>, <code>"pairing"</code>, or <code>"open"</code></td></tr>
        </table>

        <h3>dmPolicy</h3>
        <p>Controls what happens when an unrecognized sender messages the bot on a channel.</p>
        <table class="cfg-table">
            <tr><th>Value</th><th>Behavior</th></tr>
            <tr><td>"allowlist"</td><td>Check <code>allowFrom</code> + pairing store. Silently drop unrecognized senders. This is the default and preserves the original behavior.</td></tr>
            <tr><td>"pairing"</td><td>Check <code>allowFrom</code> + pairing store. If unknown, generate an 8-character pairing code and send it to the sender. The bot owner can then approve with <code>oxicrab pairing approve {channel} {code}</code>.</td></tr>
            <tr><td>"open"</td><td>Allow all senders unconditionally. No access checks are performed.</td></tr>
        </table>
        <p>See <a href="channels.html#common-patterns">Channel Setup &rarr; Common patterns</a> for a detailed walkthrough and access check flowchart.</p>

        <h3>Channel-specific fields</h3>
        <p>Each channel has additional required fields. See <a href="channels.html">Channel Setup</a> for the complete config blocks. Quick reference:</p>
        <table class="cfg-table">
            <tr><th>Channel</th><th>Required Fields</th></tr>
            <tr><td>telegram</td><td><code>token</code>. Optional: <code>proxy</code></td></tr>
            <tr><td>discord</td><td><code>token</code></td></tr>
            <tr><td>slack</td><td><code>botToken</code>, <code>appToken</code></td></tr>
            <tr><td>whatsapp</td><td>(none &mdash; scan QR on first run)</td></tr>
            <tr><td>twilio</td><td><code>accountSid</code>, <code>authToken</code>, <code>phoneNumber</code>, <code>webhookPort</code>, <code>webhookPath</code>, <code>webhookUrl</code></td></tr>
        </table>
    </div>

    <!-- LOGGING -->
    <div id="logging" class="cfg-section">
        <h2>Logging</h2>
        <p>Logging is controlled by the <code>RUST_LOG</code> environment variable. Oxicrab uses the <a href="https://docs.rs/tracing-subscriber/latest/tracing_subscriber/struct.EnvFilter.html">tracing-subscriber</a> format.</p>

        <pre><span class="hl-comment"># Default: info level, noisy dependencies suppressed</span>
./target/release/oxicrab gateway

<span class="hl-comment"># Debug logging</span>
RUST_LOG=debug ./target/release/oxicrab gateway

<span class="hl-comment"># Custom filtering</span>
RUST_LOG=info,whatsapp_rust=warn,oxicrab::channels=debug ./target/release/oxicrab gateway</pre>

        <p>Common filters:</p>
        <ul class="plain">
            <li><code>RUST_LOG=debug</code> &mdash; verbose, includes all oxicrab internals</li>
            <li><code>RUST_LOG=info,whatsapp_rust=warn</code> &mdash; suppress noisy WhatsApp crate logs</li>
            <li><code>RUST_LOG=oxicrab::agent=debug</code> &mdash; debug only the agent loop</li>
        </ul>
    </div>

</div>

<footer>
  <div class="footer-inner">
    <a href="index.html" class="nav-logo" style="font-size: 0.95rem;"><img src="oxicrab.png" alt="" width="24" height="24"><span class="oxi">oxi</span>crab</a>
    <div class="footer-links">
      <a href="https://github.com/oxicrab/oxicrab">GitHub</a>
      <a href="https://crates.io/crates/oxicrab">crates.io</a>
      <a href="https://github.com/oxicrab/oxicrab/blob/main/README.md">README</a>
      <a href="https://github.com/oxicrab/oxicrab/blob/main/LICENSE">MIT License</a>
    </div>
    <span class="footer-copy">Built by <a href="https://github.com/oxicrab" style="color: var(--accent); text-decoration: none;">James Turnbull</a></span>
  </div>
</footer>

</body>
</html>
